{
    "version": "https://jsonfeed.org/version/1",
    "title": "Guto@Site",
    "description": "",
    "home_page_url": "https://gutocarvalho.net",
    "feed_url": "https://gutocarvalho.net/feed.json",
    "user_comment": "",
    "author": {
        "name": "Guto Carvalho"
    },
    "items": [
        {
            "id": "https://gutocarvalho.net/usando-efs-em-um-cluster-k8s-ec2/",
            "url": "https://gutocarvalho.net/usando-efs-em-um-cluster-k8s-ec2/",
            "title": "DROPS: Usando EFS em um Cluster K8S EC2",
            "summary": "Aprenda a usar o EFS Provisioner em um Cluster K8S EC2/RKE. São&hellip;",
            "content_html": "<p>Aprenda a usar o EFS Provisioner em um Cluster K8S EC2/RKE.</p>\n<hr>\n<h3 id=\"o-que-são-drops\">O que são drops?</h3>\n<p>São DUMPs mentais rápidos e rasteiros, simples e objetivos – que funcionam. </p>\n<p>Geralmente de algo que eu acabei de fazer.</p>\n<p>Eu – quase sempre – volto para detalhar mais cada passo.</p>\n<p>Considere com a mesma qualidade de um rascunho ou uma anotação rápida.</p>\n<p>De qualquer forma comenta ai qquer coisa, os comentários estão ligados nos DROPS ;)</p>\n<h3 id=\"veio-a-demanda\">Veio a Demanda!</h3>\n<p>A ideia é instalar um EFS Provisioner no cluster para poder subir APPS que montam o mesmo volume em diferentes PODs.</p>\n<h3 id=\"então-comofaz\">Então ComoFaz?</h3>\n<p>Crie o arquivo instala_efs_provisioner.yaml</p>\n<pre><code>vim aplica.yaml\n</code></pre>\n<p>Insira o conteúdo abaixo</p>\n<pre><code>---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: efs-provisioner-runner\nrules:\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;persistentvolumes&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;persistentvolumeclaims&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]\n  - apiGroups: [&quot;storage.k8s.io&quot;]\n    resources: [&quot;storageclasses&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;events&quot;]\n    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: run-efs-provisioner\nsubjects:\n  - kind: ServiceAccount\n    name: efs-provisioner\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: efs-provisioner-runner\n  apiGroup: rbac.authorization.k8s.io\n---\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: leader-locking-efs-provisioner\nrules:\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;endpoints&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: leader-locking-efs-provisioner\nsubjects:\n  - kind: ServiceAccount\n    name: efs-provisioner\n    namespace: kube-system\nroleRef:\n  kind: Role\n  name: leader-locking-efs-provisioner\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: efs-provisioner\n---\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: efs-provisioner\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: efs-provisioner\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: efs-provisioner\n    spec:\n      serviceAccount: efs-provisioner\n      containers:\n        - name: efs-provisioner\n          image: quay.io/external_storage/efs-provisioner:latest\n          env:\n            - name: FILE_SYSTEM_ID\n              valueFrom:\n                configMapKeyRef:\n                  name: efs-provisioner\n                  key: file.system.id\n            - name: AWS_REGION\n              valueFrom:\n                configMapKeyRef:\n                  name: efs-provisioner\n                  key: aws.region\n            - name: DNS_NAME\n              valueFrom:\n                configMapKeyRef:\n                  name: efs-provisioner\n                  key: dns.name\n                  optional: true\n            - name: PROVISIONER_NAME\n              valueFrom:\n                configMapKeyRef:\n                  name: efs-provisioner\n                  key: provisioner.name\n          volumeMounts:\n            - name: pv-volume\n              mountPath: /persistentvolumes\n      volumes:\n        - name: pv-volume\n          nfs:\n            server: fs-&lt;ID DO SEU EFS&gt;.efs.&lt;REGIAO AWS&gt;.amazonaws.com\n            path: /\n---\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: aws-efs\nprovisioner: nativetrail.io/aws-efs\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: efs-provisioner\ndata:\n  file.system.id: fs-&lt;ID DO SEU EFS&gt;\n  aws.region: &lt;REGIAO AWS&gt;\n  provisioner.name: nativetrail.io/aws-efs\n  dns.name: &quot;&quot;\n</code></pre>\n<p>Ajuste o ID do seu EFS e região da AWS no manifesto acima, e prestenção, tem que o usar o namespace <strong>kube-system</strong> pois ele é especificado nas <strong>roles</strong> e <strong>serviceaccount</strong>, se instalar o deployment em outro namespace não vai funcionar.</p>\n<pre><code>kubectl apply -f instala_efs_provisioner.yaml -n kube-system\n    \n</code></pre>\n<p>Pronto, vamos verificar</p>\n<pre><code>kubectl get sc\n</code></pre>\n<p>Saída esperada</p>\n<pre><code>NAME                PROVISIONER              RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\naws-efs             nativetrail.io/aws-efs   Delete          Immediate           false                  43m\naws-ebs (default)   ebs.csi.aws.com          Delete          Immediate           false                  3d16h\n</code></pre>\n<p>agora vamos testar, crie o manifesto valida-pod-efs.ym com o conteúdo abaixo</p>\n<pre><code>---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: valida-aws-efs\nspec:\n  accessModes:\n    - ReadWriteMany\n  storageClassName: aws-efs\n  resources:\n    requests:\n      storage: 1Gi\n</code></pre>\n<p>aplique</p>\n<pre><code>kubectl apply -f pod-efs.yaml\n</code></pre>\n<p>saída</p>\n<pre><code>persistentvolumeclaim/valida-aws-efs created\n</code></pre>\n<p>vamos ver</p>\n<pre><code>kubectl get pvc valida-aws-efs\n</code></pre>\n<p>saída</p>\n<pre><code>NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nvalida-aws-efs   Bound    pvc-c524234f-4b07-4248-b328-c6c164dddbc2   1Gi        RWX            aws-efs        3m42s\n</code></pre>\n<p>agora com mais detalhes</p>\n<pre><code>kubectl describe pvc valida-aws-efs\n</code></pre>\n<p>saída</p>\n<pre><code>Name:          valida-aws-efs\nNamespace:     default\nStorageClass:  aws-efs\nStatus:        Bound\nVolume:        pvc-c524234f-4b07-4248-b328-c6c164dddbc2\nLabels:        &lt;none&gt;\nAnnotations:   pv.kubernetes.io/bind-completed: yes\n               pv.kubernetes.io/bound-by-controller: yes\n               volume.beta.kubernetes.io/storage-provisioner: nativetrail.io/aws-efs\nFinalizers:    [kubernetes.io/pvc-protection]\nCapacity:      1Gi\nAccess Modes:  RWX\nVolumeMode:    Filesystem\nUsed By:       &lt;none&gt;\nEvents:\n  Type    Reason                 Age                    From                                                                                   Message\n  ----    ------                 ----                   ----                                                                                   -------\n  Normal  Provisioning           3m49s                  nativetrail.io/aws-efs_efs-provisioner-644f9f8c8c-n6n48_be97e87c-7e5b-4b42-8756-2adb23a5a105  External provisioner is provisioning volume for claim &quot;default/valida-aws-efs&quot;\n  Normal  ProvisioningSucceeded  3m49s                  nativetrail.io/aws-efs_efs-provisioner-644f9f8c8c-n6n48_be97e87c-7e5b-4b42-8756-2adb23a5a105  Successfully provisioned volume pvc-c524234f-4b07-4248-b328-c6c164dddbc2\n</code></pre>\n<p>Perfeito, tudo funcionando, agora é só usar!</p>\n<p>:)</p>\n<h3 id=\"refs\">refs</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/rke\">https://github.com/rancher/rke</a></li>\n<li><a href=\"https://kubernetes.io/pt-br/\">https://kubernetes.io/pt-br/</a></li>\n<li><a href=\"https://aws.amazon.com/efs/\">https://aws.amazon.com/efs/</a></li>\n<li><a href=\"https://github.com/kubernetes-retired/external-storage/tree/master/aws/efs\">https://github.com/kubernetes-retired/external-storage/tree/master/aws/efs</a></li>\n<li><a href=\"https://icicimov.github.io/blog/virtualization/Kubernetes-NFS-shared-storage-in-AWS-with-EFS/\">https://icicimov.github.io/blog/virtualization/Kubernetes-NFS-shared-storage-in-AWS-with-EFS/</a></li>\n</ul>\n",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "K8S",
                   "Drops"
            ],
            "date_published": "2021-10-24T11:06:27-03:00",
            "date_modified": "2021-10-25T08:03:34-03:00"
        },
        {
            "id": "https://gutocarvalho.net/centralizando-logs-do-k8s-com-o-loki/",
            "url": "https://gutocarvalho.net/centralizando-logs-do-k8s-com-o-loki/",
            "title": "DROPS: Centralizando Logs do K8S com o Loki",
            "summary": "Aprenda a instalar o LOKI da GrafanaLabs para centralizar Logs do K8S.",
            "content_html": "<p>Aprenda a instalar o LOKI da GrafanaLabs para centralizar Logs do K8S.</p>\n<hr>\n<h3 id=\"o-que-são-drops\">O que são drops?</h3>\n<p>São DUMPs mentais rápidos e rasteiros, simples e objetivos – que funcionam. </p>\n<p>Geralmente de algo que eu acabei de fazer.</p>\n<p>Eu – quase sempre – volto para detalhar mais cada passo.</p>\n<p>Considere com a mesma qualidade de um rascunho ou uma anotação rápida.</p>\n<p>De qualquer forma comenta ai qquer coisa, os comentários estão ligados nos DROPS ;)</p>\n<h3 id=\"demanda\">Demanda!</h3>\n<p>A ideia é instalar um Loki no cluster K8S e começar a centralizar e consumir os logs via dashboard do grafana.</p>\n<h3 id=\"por-que-o-loki\">Por que o Loki?</h3>\n<p>O Loki é leve – em resumo esse é o maior e melhor motivo para usar ele.</p>\n<p>Comparando com outras STACKS, ele nao leva 1/3 ou 2/3 do seu cluster só para centralizar logs.</p>\n<p>Você acompanha os logs pelo Grafana Dashboard, simples e direto.</p>\n<p>Além disso o projeto tem 14 mil estrelas no GitHub e mais de 400 contribuidores :)</p>\n<p>Conheça mais do projeto, dá um chance vai :)</p>\n<ul>\n<li><a href=\"https://grafana.com/docs/loki/latest/overview/\">https://grafana.com/docs/loki/latest/overview/</a></li>\n<li><a href=\"https://grafana.com/docs/loki/latest/overview/comparisons/\">https://grafana.com/docs/loki/latest/overview/comparisons/</a></li>\n</ul>\n<h3 id=\"antes-de-começar\">Antes de começar</h3>\n<p>Estou partindo do pressuposto de que você não tem o grafana instalado!</p>\n<p>Precisa ter o Helm instalado e um cluster k8s funcional.</p>\n<h3 id=\"então-comofaz\">Então ComoFaz?</h3>\n<p>adicione o repositorio e atualize os índices</p>\n<pre><code>helm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n</code></pre>\n<p>instale o loki</p>\n<pre><code>helm upgrade --install loki --namespace=loki grafana/loki alertmanager.persistentVolume.enabled=true\n</code></pre>\n<p>instale o grafana</p>\n<pre><code>helm install loki-grafana grafana/grafana\n</code></pre>\n<p>pegue a senha de admin do grafana</p>\n<pre><code>kubectl get secret --namespace &lt;YOUR-NAMESPACE&gt; loki-grafana -o jsonpath=&quot;{.data.admin-password}&quot; | base64 --decode ; echo\n</code></pre>\n<p>crie um port-forward para acessar o grafana</p>\n<pre><code>kubectl port-forward --namespace &lt;YOUR-NAMESPACE&gt; service/loki-grafana 3000:80\n</code></pre>\n<p>acesse o grafana</p>\n<pre><code>http://localhost:3000\n</code></pre>\n<p>adicione o datasource conforme a doc abaixo</p>\n<ul>\n<li><a href=\"https://grafana.com/docs/loki/latest/getting-started/grafana/\">https://grafana.com/docs/loki/latest/getting-started/grafana/</a></li>\n</ul>\n<p>Pronto, divirta-se!</p>\n<h3 id=\"refs\">Refs</h3>\n<ul>\n<li><a href=\"https://grafana.com/docs/loki/latest/installation/helm/\">https://grafana.com/docs/loki/latest/installation/helm/</a></li>\n<li><a href=\"https://grafana.com/go/webinar/loki-getting-started-emea\">https://grafana.com/go/webinar/loki-getting-started-emea</a></li>\n<li><a href=\"https://grafana.com/blog/2020/10/28/loki-2.0-released-transform-logs-as-youre-querying-them-and-set-up-alerts-within-loki\">https://grafana.com/blog/2020/10/28/loki-2.0-released-transform-logs-as-youre-querying-them-and-set-up-alerts-within-loki</a></li>\n</ul>\n",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "Projetos",
                   "Drops"
            ],
            "date_published": "2021-10-22T09:43:24-03:00",
            "date_modified": "2021-10-22T09:47:50-03:00"
        },
        {
            "id": "https://gutocarvalho.net/drops-instalando-rancher-26-em-ha/",
            "url": "https://gutocarvalho.net/drops-instalando-rancher-26-em-ha/",
            "title": "DROPS: Instalando Rancher 2.6 em HA",
            "summary": "Aprenda a instalar o novíssimo Rancher 2.6 em modo HA. São DUMPs&hellip;",
            "content_html": "<p>Aprenda a instalar o novíssimo Rancher 2.6 em modo HA.</p>\n<hr>\n<h3 id=\"o-que-são-drops\">O que são drops?</h3>\n<p>São DUMPs mentais rápidos e rasteiros, simples e objetivos – que funcionam. </p>\n<p>Geralmente de algo que eu acabei de fazer.</p>\n<p>Eu – quase sempre – volto para detalhar mais cada passo.</p>\n<p>Considere com a mesma qualidade de um rascunho ou uma anotação rápida.</p>\n<p>De qualquer forma comenta ai qquer coisa, os comentários estão ligados nos DROPS ;)</p>\n<h2 id=\"demanda\">Demanda!</h2>\n<p>A ideia é instalar um Rancher em HA, cluster de 3 nodes, usando instâncias AWS EC2.</p>\n<h2 id=\"comofaz\">ComoFaz?</h2>\n<h3 id=\"antes-de-começar\">antes de começar</h3>\n<p>Confere aí :)</p>\n<ol>\n<li>Tenha o Kubectl instalado</li>\n<li>Tenha o RKE instalado</li>\n<li>Tenha o Helm instalado</li>\n<li>Tenha Conta na AWS</li>\n<li>Internet é de bom tom :)</li>\n</ol>\n<h3 id=\"instâncias-ec2\">instâncias ec2</h3>\n<p>Vamos lá!</p>\n<ol>\n<li>crie um chave ssh no ec2</li>\n<li>crie 3 instâncias EC2 em sua conta AWS com essa chave ssh</li>\n<li>crie 2 target groups rancher-80 e rancher-443 apontando para as máquinas do cluster</li>\n<li>crie o load balancer NLB com dois listeners apontando para os target groups rancher-80 e rancher-443</li>\n<li>crie uma entrada de dns <strong>rancher.seudominio.tld</strong> apontando para o CNAME do Load Balancer</li>\n<li>crie um security group para liberar acesso a porta 80 e 443 as máquinas do cluster</li>\n<li>crie um security group para que voce possa instalar o cluster a partir do seu IP via rke (all ports).</li>\n</ol>\n<h3 id=\"preparando-instâncias\">preparando instâncias</h3>\n<p>instale docker nas 3 maquinas</p>\n<pre><code>curl https://releases.rancher.com/install-docker/20.10.sh | sh\n</code></pre>\n<p>habilite e inicie</p>\n<pre><code>systemctl enable docker &amp;&amp; systemctl start docker\n</code></pre>\n<p>coloque o ubuntu no grupo docker</p>\n<pre><code>gpasswd -a ubuntu docker\n</code></pre>\n<h3 id=\"preparando-e-instalando-o-cluster-da-sua-máquina\">preparando e instalando o cluster (da sua máquina)</h3>\n<p>criando configuracao</p>\n<pre><code>rke config\n</code></pre>\n<p>ele vai te fazer umas perguntinhas, cadastre apenas 1 node para facilitar, eu usei 1.1.1.1 como exemplo, aponte o local da sua chave ssh, a mesma que usou nos EC2.</p>\n<pre><code>[+] Cluster Level SSH Private Key Path [~/.ssh/id_rsa]:\n[+] Number of Hosts [1]:\n[+] SSH Address of host (1) [none]: 1.1.1.1\n[+] SSH Port of host (1) [22]:\n[+] SSH Private Key Path of host (1.1.1.1) [none]:\n[-] You have entered empty SSH key path, trying fetch from SSH key parameter\n[+] SSH Private Key of host (1.1.1.1) [none]:\n[-] You have entered empty SSH key, defaulting to cluster level SSH key: ~/.ssh/id_rsa\n[+] SSH User of host (1.1.1.1) [ubuntu]:\n[+] Is host (1.1.1.1) a Control Plane host (y/n)? [y]: y\n[+] Is host (1.1.1.1) a Worker host (y/n)? [n]: y\n[+] Is host (1.1.1.1) an etcd host (y/n)? [n]: y\n[+] Override Hostname of host (1.1.1.1) [none]:\n[+] Internal IP of host (1.1.1.1) [none]:\n[+] Docker socket path on host (1.1.1.1) [/var/run/docker.sock]:\n[+] Network Plugin Type (flannel, calico, weave, canal, aci) [canal]:\n[+] Authentication Strategy [x509]:\n[+] Authorization Mode (rbac, none) [rbac]:\n[+] Kubernetes Docker image [rancher/hyperkube:v1.21.5-rancher1]:\n[+] Cluster domain [cluster.local]:\n[+] Service Cluster IP Range [10.43.0.0/16]:\n[+] Enable PodSecurityPolicy [n]:\n[+] Cluster Network CIDR [10.42.0.0/16]:\n[+] Cluster DNS Service IP [10.43.0.10]:\n[+] Add addon manifest URLs or YAML files [no]:\n</code></pre>\n<p>abra o arquivo e coloque os demais nodos, não se esqueça de cadastrar o ip privado também, depois que finalizar com os nodos, personalize o que for necessário para seu ambiente k8s, o rke é beeem flexível quanto a isso, além de ser o instalador de k8s mais fácil que eu conheço.</p>\n<pre><code>nodes:\n- address: 1.1.1.1\n  port: &quot;22&quot;\n  internal_address: &quot;172.31.1.1&quot;\n  role:\n  - controlplane\n  - worker\n  - etcd\n  hostname_override: &quot;rancher_a&quot;\n  user: ubuntu\n  docker_socket: /var/run/docker.sock\n  ssh_key: &quot;&quot;\n  ssh_key_path: ~/.ssh/id_rsa\n  ssh_cert: &quot;&quot;\n  ssh_cert_path: &quot;&quot;\n  labels: {}\n  taints: []\n- address: 2.2.2.2\n  port: &quot;22&quot;\n  internal_address: &quot;172.31.1.2&quot;\n  role:\n  - controlplane\n  - worker\n  - etcd\n  hostname_override: &quot;rancher_b&quot;\n  user: ubuntu\n  docker_socket: /var/run/docker.sock\n  ssh_key: &quot;&quot;\n  ssh_key_path: ~/.ssh/id_rsa\n  ssh_cert: &quot;&quot;\n  ssh_cert_path: &quot;&quot;\n  labels: {}\n  taints: []\n- address: 3.3.3.3\n  port: &quot;22&quot;\n  internal_address: &quot;172.31.1.3&quot;\n  role:\n  - controlplane\n  - worker\n  - etcd\n  hostname_override: &quot;rancher_c&quot;\n  user: ubuntu\n  docker_socket: /var/run/docker.sock\n  ssh_key: &quot;&quot;\n  ssh_key_path: ~/.ssh/id_rsa\n  ssh_cert: &quot;&quot;\n  ssh_cert_path: &quot;&quot;\n  labels: {}\n  taints: []\nservices:\n  etcd:\n    image: &quot;&quot;\n    extra_args: {}\n    extra_binds: []\n    extra_env: []\n    win_extra_args: {}\n    win_extra_binds: []\n    win_extra_env: []\n    external_urls: []\n    ca_cert: &quot;&quot;\n    cert: &quot;&quot;\n    key: &quot;&quot;\n    path: &quot;&quot;\n    uid: 0\n    gid: 0\n    snapshot: null\n    retention: &quot;&quot;\n    creation: &quot;&quot;\n    backup_config: null\n  kube-api:\n    image: &quot;&quot;\n    extra_args: {}\n    extra_binds: []\n    extra_env: []\n    win_extra_args: {}\n    win_extra_binds: []\n    win_extra_env: []\n    service_cluster_ip_range: 10.43.0.0/16\n    service_node_port_range: &quot;&quot;\n    pod_security_policy: false\n    always_pull_images: false\n    secrets_encryption_config: null\n    audit_log: null\n    admission_configuration: null\n    event_rate_limit: null\n  kube-controller:\n    image: &quot;&quot;\n    extra_args: {}\n    extra_binds: []\n    extra_env: []\n    win_extra_args: {}\n    win_extra_binds: []\n    win_extra_env: []\n    cluster_cidr: 10.42.0.0/16\n    service_cluster_ip_range: 10.43.0.0/16\n  scheduler:\n    image: &quot;&quot;\n    extra_args: {}\n    extra_binds: []\n    extra_env: []\n    win_extra_args: {}\n    win_extra_binds: []\n    win_extra_env: []\n  kubelet:\n    image: &quot;&quot;\n    extra_args: {}\n    extra_binds: []\n    extra_env: []\n    win_extra_args: {}\n    win_extra_binds: []\n    win_extra_env: []\n    cluster_domain: cluster.local\n    infra_container_image: &quot;&quot;\n    cluster_dns_server: 10.43.0.10\n    fail_swap_on: false\n    generate_serving_certificate: false\n  kubeproxy:\n    image: &quot;&quot;\n    extra_args: {}\n    extra_binds: []\n    extra_env: []\n    win_extra_args: {}\n    win_extra_binds: []\n    win_extra_env: []\nnetwork:\n  plugin: canal\n  options: {}\n  mtu: 0\n  node_selector: {}\n  update_strategy: null\n  tolerations: []\nauthentication:\n  strategy: x509\n  sans: []\n  webhook: null\naddons: &quot;&quot;\naddons_include: []\nsystem_images:\n  etcd: rancher/mirrored-coreos-etcd:v3.4.16-rancher1\n  alpine: rancher/rke-tools:v0.1.78\n  nginx_proxy: rancher/rke-tools:v0.1.78\n  cert_downloader: rancher/rke-tools:v0.1.78\n  kubernetes_services_sidecar: rancher/rke-tools:v0.1.78\n  kubedns: rancher/mirrored-k8s-dns-kube-dns:1.17.4\n  dnsmasq: rancher/mirrored-k8s-dns-dnsmasq-nanny:1.17.4\n  kubedns_sidecar: rancher/mirrored-k8s-dns-sidecar:1.17.4\n  kubedns_autoscaler: rancher/mirrored-cluster-proportional-autoscaler:1.8.3\n  coredns: rancher/mirrored-coredns-coredns:1.8.4\n  coredns_autoscaler: rancher/mirrored-cluster-proportional-autoscaler:1.8.3\n  nodelocal: rancher/mirrored-k8s-dns-node-cache:1.18.0\n  kubernetes: rancher/hyperkube:v1.21.5-rancher1\n  flannel: rancher/mirrored-coreos-flannel:v0.14.0\n  flannel_cni: rancher/flannel-cni:v0.3.0-rancher6\n  calico_node: rancher/mirrored-calico-node:v3.19.2\n  calico_cni: rancher/mirrored-calico-cni:v3.19.2\n  calico_controllers: rancher/mirrored-calico-kube-controllers:v3.19.2\n  calico_ctl: rancher/mirrored-calico-ctl:v3.19.2\n  calico_flexvol: rancher/mirrored-calico-pod2daemon-flexvol:v3.19.2\n  canal_node: rancher/mirrored-calico-node:v3.19.2\n  canal_cni: rancher/mirrored-calico-cni:v3.19.2\n  canal_controllers: rancher/mirrored-calico-kube-controllers:v3.19.2\n  canal_flannel: rancher/mirrored-coreos-flannel:v0.14.0\n  canal_flexvol: rancher/mirrored-calico-pod2daemon-flexvol:v3.19.2\n  weave_node: weaveworks/weave-kube:2.8.1\n  weave_cni: weaveworks/weave-npc:2.8.1\n  pod_infra_container: rancher/mirrored-pause:3.4.1\n  ingress: rancher/nginx-ingress-controller:nginx-0.48.1-rancher1\n  ingress_backend: rancher/mirrored-nginx-ingress-controller-defaultbackend:1.5-rancher1\n  ingress_webhook: rancher/mirrored-jettech-kube-webhook-certgen:v1.5.1\n  metrics_server: rancher/mirrored-metrics-server:v0.5.0\n  windows_pod_infra_container: rancher/kubelet-pause:v0.1.6\n  aci_cni_deploy_container: noiro/cnideploy:5.1.1.0.1ae238a\n  aci_host_container: noiro/aci-containers-host:5.1.1.0.1ae238a\n  aci_opflex_container: noiro/opflex:5.1.1.0.1ae238a\n  aci_mcast_container: noiro/opflex:5.1.1.0.1ae238a\n  aci_ovs_container: noiro/openvswitch:5.1.1.0.1ae238a\n  aci_controller_container: noiro/aci-containers-controller:5.1.1.0.1ae238a\n  aci_gbp_server_container: noiro/gbp-server:5.1.1.0.1ae238a\n  aci_opflex_server_container: noiro/opflex-server:5.1.1.0.1ae238a\nssh_key_path: ~/.ssh/id_rsa\nssh_cert_path: &quot;&quot;\nssh_agent_auth: false\nauthorization:\n  mode: rbac\n  options: {}\nignore_docker_version: null\nenable_cri_dockerd: null\nkubernetes_version: &quot;&quot;\nprivate_registries: []\ningress:\n  provider: &quot;&quot;\n  options: {}\n  node_selector: {}\n  extra_args: {}\n  dns_policy: &quot;&quot;\n  extra_envs: []\n  extra_volumes: []\n  extra_volume_mounts: []\n  update_strategy: null\n  http_port: 0\n  https_port: 0\n  network_mode: &quot;&quot;\n  tolerations: []\n  default_backend: null\n  default_http_backend_priority_class_name: &quot;&quot;\n  nginx_ingress_controller_priority_class_name: &quot;&quot;\ncluster_name: &quot;&quot;\ncloud_provider:\n  name: &quot;&quot;\nprefix_path: &quot;&quot;\nwin_prefix_path: &quot;&quot;\naddon_job_timeout: 0\nbastion_host:\n  address: &quot;&quot;\n  port: &quot;&quot;\n  user: &quot;&quot;\n  ssh_key: &quot;&quot;\n  ssh_key_path: &quot;&quot;\n  ssh_cert: &quot;&quot;\n  ssh_cert_path: &quot;&quot;\n  ignore_proxy_env_vars: false\nmonitoring:\n  provider: &quot;&quot;\n  options: {}\n  node_selector: {}\n  update_strategy: null\n  replicas: null\n  tolerations: []\n  metrics_server_priority_class_name: &quot;&quot;\nrestore:\n  restore: false\n  snapshot_name: &quot;&quot;\nrotate_encryption_key: false\ndns: null\n</code></pre>\n<p>depois de cadastrar os nodos, vamos começar o provisionamento</p>\n<pre><code>rke up —config cluster.yaml\n</code></pre>\n<p>após instalar verá a seguinte mensagem ( se tudo der certo )</p>\n<pre><code>INFO[0255] Finished building Kubernetes cluster successfully\n</code></pre>\n<p>configure o kubectl</p>\n<pre><code>export KUBECONFIG=kube_config_cluster.yml\n</code></pre>\n<p>verifique se o cluster está funcionando</p>\n<pre><code>kubctl get nodes\n</code></pre>\n<p>saída exemplo</p>\n<pre><code>NAME             STATUS   ROLES                      AGE   VERSION\n54.225.184.xxx   Ready    controlplane,etcd,worker   12m   v1.21.5\n54.243.65.xxx    Ready    controlplane,etcd,worker   12m   v1.21.5\n72.44.32.xxx     Ready    controlplane,etcd,worker   12m   v1.21.5\n</code></pre>\n<p>cluster instalado, agora verifique a saúde de seu cluster</p>\n<pre><code>kubectl get pods --all-namespaces\n</code></pre>\n<p>saída exemplo</p>\n<pre><code>NAMESPACE       NAME                                       READY   STATUS      RESTARTS   AGE\ningress-nginx   default-http-backend-6977475d9b-z64cj      1/1     Running     0          17m\ningress-nginx   nginx-ingress-controller-h4c67             1/1     Running     0          17m\ningress-nginx   nginx-ingress-controller-kjd8r             1/1     Running     0          17m\ningress-nginx   nginx-ingress-controller-q4lp2             1/1     Running     0          17m\nkube-system     calico-kube-controllers-7d5d95c8c9-mcfj6   1/1     Running     0          18m\nkube-system     canal-lsbkv                                2/2     Running     0          18m\nkube-system     canal-lwtq9                                2/2     Running     0          18m\nkube-system     canal-wm7c8                                2/2     Running     0          18m\nkube-system     coredns-55b58f978-jnfsq                    1/1     Running     0          17m\nkube-system     coredns-55b58f978-wr4w7                    1/1     Running     0          18m\nkube-system     coredns-autoscaler-76f8869cc9-lz44p        1/1     Running     0          18m\nkube-system     metrics-server-55fdd84cd4-rjk7w            1/1     Running     0          18m\nkube-system     rke-coredns-addon-deploy-job-th472         0/1     Completed   0          18m\nkube-system     rke-ingress-controller-deploy-job-59cm4    0/1     Completed   0          17m\nkube-system     rke-metrics-addon-deploy-job-94b8t         0/1     Completed   0          18m\nkube-system     rke-network-plugin-deploy-job-q5nts        0/1     Completed   0          18m\n</code></pre>\n<p>aparentemente tudo bem :)</p>\n<h3 id=\"preparando-e-instalando-o-cert-manager-neste-cluster-sua-máquina\">preparando e instalando o cert-manager neste cluster (sua máquina)</h3>\n<p>instale os crds do cert-manager</p>\n<pre><code>kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.5.1/cert-manager.crds.yaml\n</code></pre>\n<p>adicione o repo e atualize o índices</p>\n<pre><code>helm repo add jetstack https://charts.jetstack.io. \nhelm repo update\n</code></pre>\n<p>crie o namespace</p>\n<pre><code>kubectl create namespace cert-manager\n</code></pre>\n<p>instale o cert-mamanger</p>\n<pre><code>helm install cert-manager jetstack/cert-manager \\\n  --namespace cert-manager \\\n  --create-namespace \\\n  --version v1.5.1\n</code></pre>\n<p>crie o cluster issuer, sem isso ele não gera os certs via lets</p>\n<pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\n  namespace: cert-manager\nspec:\n  acme:\n    # The ACME server URL\n    server: https://acme-v02.api.letsencrypt.org/directory\n    # Email address used for ACME registration\n    email: certmanager@nativetrail.io\n    # Name of a secret used to store the ACME account private key\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    # Enable the HTTP-01 challenge provider\n    solvers:\n    - http01:\n        ingress:\n          class: nginx\n</code></pre>\n<p>aplique o issuer</p>\n<pre><code>kubectl apply -f issuer.yml\n</code></pre>\n<p>saída esperada</p>\n<pre><code> clusterissuer.cert-manager.io/letsencrypt-prod created\n</code></pre>\n<p>verifique se está ok</p>\n<pre><code>kubectl get clusterissuer \n</code></pre>\n<p>saída esperada</p>\n<pre><code>NAME               READY   AGE\nletsencrypt-prod   True    48s\n</code></pre>\n<p>se estiver mostrando “True” deu certo!</p>\n<h3 id=\"preparando-e-instalando-o-rancher-neste-cluster-na-sua-máquina\">preparando e instalando o rancher neste cluster (na sua máquina)</h3>\n<p>adicione o repo e atualize os índices</p>\n<pre><code>helm repo add rancher-latest https://releases.rancher.com/server-charts/latest\nhelm repo update\n</code></pre>\n<p>crie o namespace cattle-system</p>\n<pre><code>kubectl create namespace cattle-system\n</code></pre>\n<p>instale o rancher</p>\n<pre><code>helm install rancher rancher-latest/rancher \\\n  --namespace cattle-system \\\n  --set hostname=kloud.gr1d.io \\\n  --set replicas=3 \\\n  --set ingress.tls.source=letsEncrypt \\\n  --set letsEncrypt.email=certmanager@nativetrail.io\n</code></pre>\n<p>verifique</p>\n<pre><code>kubectl get pods -n cattle-system\n</code></pre>\n<p>saída esperada, estará criando na primeira vez que rodar o comando</p>\n<pre><code>NAME                       READY   STATUS              RESTARTS   AGE\nrancher-58b56d54df-7mv7d   0/1     ContainerCreating   0          29s\nrancher-58b56d54df-csmpl   0/1     ContainerCreating   0          29s\nrancher-58b56d54df-pkpz6   0/1     ContainerCreating   0          29s\n</code></pre>\n<p>aguarde e verifique novamente, use o mesmo comando</p>\n<pre><code>kubectl get pods -n cattle-system\n</code></pre>\n<p>saída</p>\n<pre><code>NAME                       READY   STATUS    RESTARTS   AGE\nrancher-58b56d54df-7mv7d   0/1     Running   0          41s\nrancher-58b56d54df-csmpl   0/1     Running   0          41s\nrancher-58b56d54df-pkpz6   0/1     Running   0          41s\n</code></pre>\n<p>rancher instalado e rodando!</p>\n<h3 id=\"pós-instalação\">pós instalação</h3>\n<p>observe a saída do comando helm, ele vai te dizer como pegar a senha gerada para o primeiro acesso, depois disso, acesse o rancher via web através da URL definida e siga as os procedimentos para trocar a senha e iniciar o uso do seu rancher.</p>\n<h3 id=\"refs\">refs</h3>\n<ul>\n<li><a href=\"https://rancher.com/docs/rancher/v2.6/en/installation/install-rancher-on-k8s/\">https://rancher.com/docs/rancher/v2.6/en/installation/install-rancher-on-k8s/</a></li>\n<li><a href=\"https://rancher.com/docs/rancher/v2.6/en/installation/resources/k8s-tutorials/infrastructure-tutorials/infra-for-ha/\">https://rancher.com/docs/rancher/v2.6/en/installation/resources/k8s-tutorials/infrastructure-tutorials/infra-for-ha/</a></li>\n</ul>\n<p>:)</p>\n",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "Projetos",
                   "Drops"
            ],
            "date_published": "2021-10-22T09:09:24-03:00",
            "date_modified": "2021-10-22T09:14:26-03:00"
        },
        {
            "id": "https://gutocarvalho.net/ferramentas-open-source-apm/",
            "url": "https://gutocarvalho.net/ferramentas-open-source-apm/",
            "title": "Ferramentas APM open source Self-Hosted",
            "summary": "Conheça algumas ferramentas open source para APM para seus projetos Estude e&hellip;",
            "content_html": "<p>Conheça algumas ferramentas open source para APM para seus projetos</p>\n<hr>\n<p>Estude e avalie essas boas ferramentas que você pode usar em seu projeto e infraestrutura.</p>\n<h2 id=\"apache-skywalking\">Apache Skywalking</h2>\n<p>Site do projeto: <a href=\"https://skywalking.apache.org/\">https://skywalking.apache.org/</a></p>\n<p>GitHub do projeto: 14.7k stars e 250+ contributors</p>\n<p>Recomendado para APPs rodando em Cloud e API.</p>\n<p>Se você está imerso no universo de API, microserviços, kubernetes e cloud native esse é o projeto para você, ele foi desenhado para Cloud e API sendo hoje um dos maiores, mais respeitados e ativos do GitHub.</p>\n<p>Há quem diga que é o melhor nesse segmento hoje.</p>\n<h2 id=\"pinpoint\">PinPoint</h2>\n<p>Site do projeto: <a href=\"https://github.com/naver/pinpoint\">https://github.com/naver/pinpoint</a></p>\n<p>GitHub 10.8k stars e 90+ contributors</p>\n<p>Acho que o PinPoint é o preferido da galera de JAVA em 2021, é bem conhecido e vastamente utilizado.</p>\n<p>Recomendado para APPs JAVA ou Python</p>\n<p>Baseado no Google’s Dapper.</p>\n<h2 id=\"stagemonitor\">StageMonitor</h2>\n<p>Site do projeto <a href=\"https://www.stagemonitor.org\">https://www.stagemonitor.org</a></p>\n<p>GitHub 1.6k stars e 24+ contributors</p>\n<p>Recomendado para JAVA, tem compatibilidade e integração com OpenTracing.</p>\n<h2 id=\"scouter\">Scouter</h2>\n<p>Site do projeto <a href=\"https://github.com/scouter-project/scouter\">https://github.com/scouter-project/scouter</a></p>\n<p>GitHub 1.8k starts e 40+ contributors.</p>\n<p>Inspirado no New Relic e APP Dynamics, é uma aplicação modular e bastante extensível.</p>\n<p>Oferece interações nativas com Telegraf e Zipkin.</p>\n<p>Tem agente nativo para java, linux, unix e até windows.</p>\n<p>Monitora nativamente (usando telegraph)</p>\n<ul>\n<li>Redis</li>\n<li>Nginx</li>\n<li>Apache HTTPd</li>\n<li>HAProxy</li>\n<li>Kafka</li>\n<li>MySQL</li>\n<li>MongoDB</li>\n<li>RabbitMQ</li>\n<li>ElasticSearch</li>\n<li>Kubernetes</li>\n<li>Mesos</li>\n</ul>\n<p>Instrumenta nativamente:</p>\n<ul>\n<li>C#</li>\n<li>GO</li>\n<li>Java</li>\n<li>JavaScript</li>\n<li>Ruby</li>\n<li>Scala</li>\n<li>PHP</li>\n</ul>\n<p>Instrumentação extendida via código da comunidade</p>\n<ul>\n<li>C++</li>\n<li>Python</li>\n<li>Clojure</li>\n<li>Elixir</li>\n<li>Lua</li>\n</ul>\n<p>Veja dados completos da instrumentação</p>\n<ul>\n<li><a href=\"https://zipkin.io/pages/tracers_instrumentation.html\">https://zipkin.io/pages/tracers_instrumentation.html</a> </li>\n</ul>\n<h2 id=\"app-metrics\">APP Metrics</h2>\n<p>Site do projeto <a href=\"https://www.app-metrics.io/\">https://www.app-metrics.io/</a></p>\n<p>GitHub 2k starts e 40+ contributors</p>\n<p>Recomendado para APPs .Net.</p>\n<p>Se o seu negócio é .NET o APP Metrics é a ferramenta pra você e seu time.</p>\n<h2 id=\"inspectit-ocelot\">InspectIT Ocelot</h2>\n<p>Site do projeto: <a href=\"https://github.com/inspectIT/inspectit-ocelot\">https://github.com/inspectIT/inspectit-ocelot</a></p>\n<p>GitHub 158 starts e 25+ contributors</p>\n<p>Esse é um projeto novo, o caçula da turma, mas tem muito potencial.</p>\n<p>Ele tem uma pegada na fácil configuração, aliás zero configuração e uma boa oferta nativa de métricas.</p>\n<p>E isso, bons estudos!</p>\n<p>[s]</p>\n",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "Projetos"
            ],
            "date_published": "2021-10-17T16:29:13-03:00",
            "date_modified": "2021-10-17T16:34:29-03:00"
        },
        {
            "id": "https://gutocarvalho.net/k8s-port-forward-facil/",
            "url": "https://gutocarvalho.net/k8s-port-forward-facil/",
            "title": "DROPS: Fazer Port Forward no K8S é fácil :)",
            "summary": "Aprenda a se conectar em um serviço K8S sem exposição! São DUMPs&hellip;",
            "content_html": "<p>Aprenda a se conectar em um serviço K8S sem exposição!</p>\n<hr>\n<h3 id=\"o-que-são-drops\">O que são drops?</h3>\n<p>São DUMPs mentais rápidos e rasteiros, simples e objetivos – que funcionam. </p>\n<p>Geralmente de algo que eu acabei de fazer.</p>\n<p>Eu – quase sempre – volto para detalhar mais cada passo.</p>\n<p>Considere com a mesma qualidade de um rascunho ou uma anotação rápida.</p>\n<p>De qualquer forma comenta ai qquer coisa, os comentários estão ligados nos DROPS ;)</p>\n<h3 id=\"demanda\">Demanda!</h3>\n<p>Preciso me conectar em um Mongo no cluster sem expor ele para o mundo.</p>\n<h3 id=\"comofaz\">ComoFaz?</h3>\n<p>Vamos usar o port-forward, veja como a sintaxe é simples</p>\n<pre><code>kubectl nome_do_pod porta_local:portal_cluster -n seuname_space\n</code></pre>\n<p>Exemplo!</p>\n<pre><code>kubectl mongodb-replicaset-0 28015:27017 -n seuname_space\n</code></pre>\n<p>Prontinho!</p>\n<h3 id=\"refs\">Refs</h3>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/\">https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/</a></li>\n</ul>\n",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "K8S",
                   "Drops"
            ],
            "date_published": "2021-10-15T05:43:22-03:00",
            "date_modified": "2021-10-22T09:09:30-03:00"
        },
        {
            "id": "https://gutocarvalho.net/baixando-imagens-de-ecr-privado-no-k8s/",
            "url": "https://gutocarvalho.net/baixando-imagens-de-ecr-privado-no-k8s/",
            "title": "DROPS: Baixando imagens de ECR Privado no K8S",
            "summary": "Aprenda a pegar imagens de registry ECR privado em seu cluster K8S.",
            "content_html": "<p>Aprenda a pegar imagens de registry ECR privado em seu cluster K8S.</p>\n<hr>\n<h3 id=\"o-que-são-drops\">O que são drops?</h3>\n<p>São DUMPs mentais rápidos e rasteiros, simples e objetivos – que funcionam. </p>\n<p>Geralmente de algo que eu acabei de fazer.</p>\n<p>Eu – quase sempre – volto para detalhar mais cada passo.</p>\n<p>Considere com a mesma qualidade de um rascunho ou uma anotação rápida.</p>\n<p>De qualquer forma comenta ai qquer coisa, os comentários estão ligados nos DROPS ;)</p>\n<h3 id=\"demanda\">Demanda!</h3>\n<p>Precisamos cadastrar um secret para pegar imagens de um ECR privado</p>\n<h3 id=\"comofaz\">ComoFaz?</h3>\n<p>Primeiro vamos gerar o TOKEN, você precisa do AWS CLI para isso,</p>\n<pre><code>aws configure\n</code></pre>\n<p>depois de configurado gere o TOKEN</p>\n<pre><code>aws ecr get-login-password --region us-east-1\n</code></pre>\n<p>agora vamos no K8S criar o secret</p>\n<pre><code>kubectl create secret docker-registry ecr-nativetrail \\\n  --docker-server=ID.dkr.ecr.us-east-1.amazonaws.com/ \\\n  --docker-username=AWS \\\n  --docker-password=SEU_TOKEN_GERADO_VIA_AWS_CLI \\\n  --namespace=SEU_NAMESPACE\n</code></pre>\n<p>verifique</p>\n<pre><code>kubectl get secrets -n SEU_NAMESPACE|grep ecr\n</code></pre>\n<p>saída</p>\n<pre><code>ecr-nativetrail kubernetes.io/dockerconfigjson        1      15h\n</code></pre>\n<p>Nao se esqueça de setar o secret no seu manifesto de deployment, dentro de “spec” </p>\n<pre><code>      spec:\n        imagePullSecrets:\n        - name: ecr-nativetrail\n</code></pre>\n<p>Exemplo</p>\n<pre><code>  apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    name: app-example\n  spec:\n    replicas: 1\n    selector:\n      matchLabels:\n        app: app-example\n    template:\n      metadata:\n        labels:\n          app: nativetrail\n      spec:\n        imagePullSecrets:\n        - name: ecr-nativetrail\n        containers:\n        - name: app-examp;e\n          image:  ID.dkr.ecr.us-east-1.amazonaws.com/app:latest\n</code></pre>\n<p>Prontinho!</p>\n",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "K8S",
                   "Drops"
            ],
            "date_published": "2021-10-14T12:39:31-03:00",
            "date_modified": "2021-10-15T05:55:59-03:00"
        },
        {
            "id": "https://gutocarvalho.net/storageclass-ebs-em-seu-cluster-k8s-ec2/",
            "url": "https://gutocarvalho.net/storageclass-ebs-em-seu-cluster-k8s-ec2/",
            "title": "DROPS: Storage EBS em seu Cluster K8S EC2",
            "summary": "Aprenda a usar o storage EBS como SC em seu cluster EC2!&hellip;",
            "content_html": "<p>Aprenda a usar o storage EBS como SC em seu cluster EC2!</p>\n<hr>\n<h3 id=\"o-que-são-drops\">O que são drops?</h3>\n<p>São DUMPs mentais rápidos e rasteiros, simples e objetivos – que funcionam. </p>\n<p>Geralmente de algo que eu acabei de fazer.</p>\n<p>Eu – quase sempre – volto para detalhar mais cada passo.</p>\n<p>Considere com a mesma qualidade de um rascunho ou uma anotação rápida.</p>\n<p>De qualquer forma comenta ai qquer coisa, os comentários estão ligados nos DROPS ;)</p>\n<h3 id=\"demanda\">Demanda</h3>\n<p>Configurar um storageclass EBS em um cluster K8S rodando via EC2.</p>\n<h3 id=\"comofaz\">ComoFaz?</h3>\n<p>crie o arquivo aws-ebs-secrets.yaml</p>\n<pre><code>vim ws-ebs-secrets.yaml\n</code></pre>\n<p>insira o conteúdo abaixo, e ajuste suas credenciais</p>\n<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: aws-secret\n  namespace: kube-system\nstringData:\n  key_id: &quot;SUA_ACCESS_KEY&quot;\n  access_key: &quot;SUA_SECRET_KEY&quot;\n</code></pre>\n<p>aplique o manifesto</p>\n<pre><code>kubectl apply -f aws-ebs-secrets.yaml\n</code></pre>\n<p>agora instale o driver ebs</p>\n<pre><code>kubectl apply -k &quot;github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.4&quot;\n</code></pre>\n<p>saída esperada</p>\n<pre><code>serviceaccount/ebs-csi-controller-sa created\nserviceaccount/ebs-csi-node-sa created\nclusterrole.rbac.authorization.k8s.io/ebs-csi-node-role created\nclusterrole.rbac.authorization.k8s.io/ebs-external-attacher-role created\nclusterrole.rbac.authorization.k8s.io/ebs-external-provisioner-role created\nclusterrole.rbac.authorization.k8s.io/ebs-external-resizer-role created\nclusterrole.rbac.authorization.k8s.io/ebs-external-snapshotter-role created\nclusterrolebinding.rbac.authorization.k8s.io/ebs-csi-attacher-binding created\nclusterrolebinding.rbac.authorization.k8s.io/ebs-csi-node-getter-binding created\nclusterrolebinding.rbac.authorization.k8s.io/ebs-csi-provisioner-binding created\nclusterrolebinding.rbac.authorization.k8s.io/ebs-csi-resizer-binding created\nclusterrolebinding.rbac.authorization.k8s.io/ebs-csi-snapshotter-binding created\ndeployment.apps/ebs-csi-controller created\npoddisruptionbudget.policy/ebs-csi-controller created\ndaemonset.apps/ebs-csi-node created\ncsidriver.storage.k8s.io/ebs.csi.aws.com created\n</code></pre>\n<p>verifique se tá tudo bem</p>\n<pre><code>kubectl get pods -n kube-system|grep ebs\n</code></pre>\n<p>saída esperada</p>\n<pre><code>ebs-csi-controller-7c486f7676-826ph        6/6     Running     0          110s\nebs-csi-controller-7c486f7676-l5wsg        6/6     Running     0          110s\nebs-csi-node-5q7lk                         3/3     Running     0          108s\nebs-csi-node-cxv4p                         3/3     Running     0          109s\nebs-csi-node-fskfw                         3/3     Running     0          108s\n</code></pre>\n<p>tá tudo bem, agora crie o manifesto do storageclass</p>\n<pre><code>vim ebs-storageclass.yaml\n</code></pre>\n<p>insira o conteúdo abaixo</p>\n<pre><code>kind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: ebs-storageclass\nparameters:\n  type: gp2\nprovisioner: ebs.csi.aws.com\nvolumeBindingMode: Immediate\n</code></pre>\n<p>aplique o manifesto</p>\n<pre><code>kubectl apply -f ebs-storageclass.yaml\n</code></pre>\n<p>verifique se criou o sc</p>\n<pre><code>kubectl get sc\n</code></pre>\n<p>saída esperada</p>\n<pre><code>NAME                         PROVISIONER       RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\nebs-storageclass             ebs.csi.aws.com   Delete          Immediate   false                  3m24s\n</code></pre>\n<p>caso queira, defina este sc como default</p>\n<pre><code>  kubectl patch storageclass ebs-storageclass -p &#39;{&quot;metadata&quot;: {&quot;annotations&quot;:{&quot;storageclass.kubernetes.io/is-default-class&quot;:&quot;true&quot;}}}\n</code></pre>\n<p>prontinho! :)</p>\n",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "K8S",
                   "Drops"
            ],
            "date_published": "2021-10-13T18:45:57-03:00",
            "date_modified": "2021-10-20T16:49:46-03:00"
        },
        {
            "id": "https://gutocarvalho.net/drops-criando-um-eks-basico-via-terraform/",
            "url": "https://gutocarvalho.net/drops-criando-um-eks-basico-via-terraform/",
            "title": "DROPS: Criando um eks básico via terraform",
            "summary": "Aprenda a criar um cluster EKS básico via Terraform! Só vem :”)&hellip;",
            "content_html": "<p>Aprenda a criar um cluster EKS básico via Terraform! Só vem :”)</p>\n<h3 id=\"o-que-são-drops\">O que são drops?</h3>\n<p>São DUMPs mentais rápidos e rasteiros, simples e objetivos – que funcionam. </p>\n<p>Geralmente eu volto para detalhar mais cada passo – com o devido tempo.</p>\n<p>Considere com a mesma qualidade de um rascunho ou uma anotação rápida.</p>\n<p>De qualquer forma comenta ai qquer coisa, os comentários estão ligados nos DROPS ;)</p>\n<hr>\n<h3 id=\"requisitos\">requisitos</h3>\n<p>Tenha kubeclt e helm instalados.</p>\n<p>Tenha o awscli e aws-iam-authenticator instalados.</p>\n<p>Esteja logado com aws-cli na conta correta com permissoes para criar o EKS.</p>\n<p>Quais permissões?</p>\n<ul>\n<li><a href=\"https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/docs/iam-permissions.md\">https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/docs/iam-permissions.md</a></li>\n</ul>\n<h3 id=\"crie-um-diretório-para-seu-projeto\">crie um diretório para seu projeto</h3>\n<pre><code>mkdir -p terraform/eks/meucluster\ncd terraform/eks/meucluster\n</code></pre>\n<h3 id=\"crie-o-arquivo-para-definir-as-versões-dos-módulos\">crie o arquivo para definir as versões dos módulos</h3>\n<p>edite o arquiovo</p>\n<pre><code>vim defaults.tf\n</code></pre>\n<p>insira o conteúdo abaixo para definir der forma clara as versões que vamos usar</p>\n<pre><code>terraform {\n  required_version = &quot;&gt;= 0.13.1&quot;\n\n  required_providers {\n    aws        = &quot;&gt;= 3.62.0&quot;\n    local      = &quot;&gt;= 2.1.0&quot;\n    kubernetes = &quot;&gt;= 2.5.0&quot;\n    cloudinit  = &quot;&gt;= 2.2.0&quot;\n    http = {\n      source  = &quot;terraform-aws-modules/http&quot;\n      version = &quot;&gt;= 2.4.1&quot;\n    }\n  }\n}\n\nprovider &quot;aws&quot; {\n  region  = &quot;us-east-1&quot;\n}\n\ndata &quot;aws_caller_identity&quot; &quot;current&quot; {} # used for accesing Account ID and ARN\n</code></pre>\n<p>valide</p>\n<pre><code>terraform validate\n</code></pre>\n<p>saída esperada</p>\n<pre><code>Success! The configuration is valid.\n</code></pre>\n<h3 id=\"crie-o-arquivo-com-as-variáveis-que-vão-configurar-a-vpc-e-o-eks\">crie o arquivo com as variáveis que vão configurar a vpc e o eks</h3>\n<p>crie o arquivo</p>\n<pre><code>vim configs.tfvars\n</code></pre>\n<p>coloque o conteúdo</p>\n<pre><code>## configuracoes para vpc\n\ncluster_name            = &quot;hackathon&quot;\nname_prefix             = &quot;hackathon&quot;\nmain_network_block      = &quot;10.0.0.0/16&quot;\nsubnet_prefix_extension = 4\nzone_offset             = 8\n\n## configuracoes para eks\n\neks_cluster_version = &quot;1.21&quot;\n\nnode_group_default_disk_size = 30\nnode_group_default_ami_type = &quot;AL2_x86_64&quot;\n    \nnode_group_desired_capacity = 1\nnode_group_max_capacity = 8\nnode_group_min_capacity = 1\nnode_group_max_unavailable_percentage = 50\n    \nnode_group_capacity_type = &quot;ON_DEMAND&quot;\nnode_group_instance_type = &quot;t3.large&quot;\n</code></pre>\n<p>valide</p>\n<pre><code>terraform validate\n</code></pre>\n<p>saída esperada</p>\n<pre><code>Success! The configuration is valid.\n</code></pre>\n<h3 id=\"crie-o-manifesto-que-vai-criar-e-configurar-a-vpc\">crie o manifesto que vai criar e configurar a VPC</h3>\n<p>vamos criar agora a vpc</p>\n<pre><code>vim vpc.tl\n</code></pre>\n<p>insira o conteúdo abaixo</p>\n<pre><code># Declarando variaveis\n\nvariable &quot;cluster_name&quot; {\n  type        = string\n  description = &quot;Nome do Cluster&quot;\n}\n\nvariable &quot;name_prefix&quot; {\n  type        = string\n  description = &quot;Prefixo que será utilizado nos nomes dos objetos de infraestrutura criados na AWS&quot;\n}\n\nvariable &quot;main_network_block&quot; {\n  type        = string\n  description = &quot;Bloco CIDR base que sera usado em sua VPC&quot;\n}\n\nvariable &quot;subnet_prefix_extension&quot; {\n  type        = number\n  description = &quot;Bits de extensao do seu bloco CIDR que sera usado para calcular as suberedes&quot;\n}\n\nvariable &quot;zone_offset&quot; {\n  type        = number\n  description = &quot;Offset de extensao dos bits CIDR para calculo e subnets, para evitar colisoes entre redes publicas e privadas&quot;\n}\n\n# Fixando o IP do Nat Gateway\n\nresource &quot;aws_eip&quot; &quot;nat_gw_elastic_ip&quot; {\n  vpc = true\n  tags = {\n    Name            = &quot;${var.cluster_name}-nat-eip&quot;\n  }\n}\n\n# Criando a VPC usando configs do modulo oficial AWS\n\nmodule &quot;vpc&quot; {\n  source  = &quot;terraform-aws-modules/vpc/aws&quot;\n\n  name = &quot;${var.name_prefix}-vpc&quot;\n  cidr = var.main_network_block\n  azs  = [ &quot;us-east-1a&quot;, &quot;us-east-1b&quot;, &quot;us-east-1c&quot;, &quot;us-east-1d&quot; ]\n\n  private_subnets      = [&quot;10.0.1.0/24&quot;, &quot;10.0.2.0/24&quot;, &quot;10.0.3.0/24&quot;, &quot;10.0.4.0/24&quot; ]\n  public_subnets       = [&quot;10.0.5.0/24&quot;, &quot;10.0.6.0/24&quot;, &quot;10.0.7.0/24&quot;, &quot;10.0.8.0/24&quot; ]\n\n  enable_nat_gateway     = true\n  single_nat_gateway     = true\n  one_nat_gateway_per_az = false\n  enable_dns_hostnames   = true\n  reuse_nat_ips          = true\n  external_nat_ip_ids    = [aws_eip.nat_gw_elastic_ip.id]\n\n  # Adicionando tags necessarias para o EKS\n\n  tags = {\n    &quot;kubernetes.io/cluster/${var.cluster_name}&quot; = &quot;shared&quot;\n  }\n  public_subnet_tags = {\n    &quot;kubernetes.io/cluster/${var.cluster_name}&quot; = &quot;shared&quot;\n    &quot;kubernetes.io/role/elb&quot;                    = &quot;1&quot;\n  }\n  private_subnet_tags = {\n    &quot;kubernetes.io/cluster/${var.cluster_name}&quot; = &quot;shared&quot;\n    &quot;kubernetes.io/role/internal-elb&quot;           = &quot;1&quot;\n  }\n}\n</code></pre>\n<p>valide</p>\n<pre><code>terraform validate\n</code></pre>\n<p>saída esperada</p>\n<pre><code>Success! The configuration is valid.\n</code></pre>\n<h3 id=\"crie-o-manifesto-que-vai-configurar-o-eks\">crie o manifesto que vai configurar o eks</h3>\n<p>crie o arquivo</p>\n<pre><code>vim eks.tf\n</code></pre>\n<p>coloque o conteúdo</p>\n<pre><code># declarando variáveis\n\nvariable &quot;eks_cluster_version&quot; {\n  type        = string\n}\n\nvariable &quot;node_group_default_disk_size&quot; {\n  type        = number\n}\n\nvariable &quot;node_group_default_ami_type&quot; {\n  type        = string\n}\n\nvariable &quot;node_group_desired_capacity&quot; {\n  type        = number\n}\n\nvariable &quot;node_group_max_capacity&quot; {\n  type        = number\n}\n\nvariable &quot;node_group_min_capacity&quot; {\n  type        = number\n}\n\nvariable &quot;node_group_max_unavailable_percentage&quot; {\n  type        = number\n}\n\nvariable &quot;node_group_capacity_type&quot; {\n  type        = string\n}\n\nvariable &quot;node_group_instance_type&quot; {\n  type        = string\n}\n\n\n# dados para configuracao\n\ndata &quot;aws_eks_cluster&quot; &quot;eks&quot; {\n  name = module.eks.cluster_id\n}\n\ndata &quot;aws_eks_cluster_auth&quot; &quot;eks&quot; {\n  name = module.eks.cluster_id\n}\n\n# configurando provider kubernetes\n\nprovider &quot;kubernetes&quot; {\n  host                   = data.aws_eks_cluster.eks.endpoint\n  cluster_ca_certificate = base64decode(data.aws_eks_cluster.eks.certificate_authority[0].data)\n  token                  = data.aws_eks_cluster_auth.eks.token\n}\n\n# configurando eks\n\nmodule &quot;eks&quot; {\n  source          = &quot;terraform-aws-modules/eks/aws&quot;\n\n  cluster_version = var.eks_cluster_version\n  cluster_name    = &quot;${var.cluster_name}&quot;\n\n  subnets = module.vpc.private_subnets\n  vpc_id  = module.vpc.vpc_id\n\n node_groups_defaults = {\n    ami_type  = var.node_group_default_ami_type\n    disk_size = var.node_group_default_disk_size\n  }\n\n  node_groups = {\n    hacka_node_group = {\n      desired_capacity = var.node_group_desired_capacity\n      max_capacity     = var.node_group_max_capacity\n      min_capacity     = var.node_group_min_capacity\n\n      instance_types = [ var.node_group_instance_type ]\n      capacity_type  = var.node_group_capacity_type\n      update_config = {\n        max_unavailable_percentage = var.node_group_max_unavailable_percentage\n      }\n    }\n  }\n\n}\n</code></pre>\n<p>valide</p>\n<pre><code>terraform validate\n</code></pre>\n<p>saída esperada</p>\n<pre><code>Success! The configuration is valid.\n</code></pre>\n<h3 id=\"crie-o-plano-de-instalação\">crie o plano de instalação</h3>\n<p>Use o arquivo configs.tfvars para construir o plano</p>\n<pre><code>terraform plan -out=plan -var-file=configs.tfvars;\n</code></pre>\n<p>saída esperada</p>\n<pre><code>.\n.\n.\n\nPlan: 54 to add, 0 to change, 0 to destroy.\n</code></pre>\n<h3 id=\"aplique-o-plano-criado\">aplique o plano criado</h3>\n<p>vamos aplicar agora</p>\n<pre><code>terraform apply plan\n</code></pre>\n<p>saída esperada</p>\n<pre><code>.\n.\n.\nApply complete! Resources: 54 added, 0 changed, 0 destroyed.\n</code></pre>\n<h3 id=\"validando-o-acesso-ao-cluster\">validando o acesso ao cluster</h3>\n<p>carregue o kubconfig</p>\n<pre><code>export KUBECONFIG=kubeconfig\nkubectl cluster-info\n</code></pre>\n<p>saída esperada</p>\n<pre><code>Kubernetes control plane is running at https://xxxx.gr7.us-east-1.eks.amazonaws.com\nCoreDNS is running at https://xxx.gr7.us-east-1.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n\nTo further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.\n</code></pre>\n<p>verifique os nodes</p>\n<pre><code>kubectl get nodes\n</code></pre>\n<p>saída esperada</p>\n<pre><code>NAME                        STATUS   ROLES    AGE     VERSION\nip-10-xx-xx-xx.ec2.internal   Ready    &lt;none&gt;   3m11s   v1.21.2-eks-55daa9d\n</code></pre>\n<p>Parece tudo ok!</p>\n<p>Agora vai na AWS e confere VPC, EKS e o restante ;)    </p>\n<h3 id=\"post-install\">post-install</h3>\n<p>Agora precisamos instalar o ingress e o cert-manager, vai lá!</p>\n<ol>\n<li><a href=\"https://gutocarvalho.net/instalando-ingress-aws-no-k8s-eks/\">https://gutocarvalho.net/instalando-ingress-aws-no-k8s-eks/</a></li>\n<li><a href=\"https://gutocarvalho.net/instalando-cert-manager-no-k8s/\">https://gutocarvalho.net/instalando-cert-manager-no-k8s/</a></li>\n</ol>\n<p>Caso precise regerar o kubeconfig</p>\n<ul>\n<li><a href=\"https://gutocarvalho.net/gerando-kubeconfig-para-aws-eks/\">https://gutocarvalho.net/gerando-kubeconfig-para-aws-eks/</a></li>\n</ul>\n<p>Bons estudos!</p>\n<h3 id=\"refs\">refs</h3>\n<ul>\n<li><a href=\"https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest\">https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest</a></li>\n<li><a href=\"https://github.com/terraform-aws-modules/terraform-aws-eks\">https://github.com/terraform-aws-modules/terraform-aws-eks</a></li>\n<li><a href=\"https://itnext.io/build-an-eks-cluster-with-terraform-d35db8005963\">https://itnext.io/build-an-eks-cluster-with-terraform-d35db8005963</a></li>\n<li><a href=\"https://adamtheautomator.com/terraform-eks-module/\">https://adamtheautomator.com/terraform-eks-module/</a></li>\n<li><a href=\"https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/docs/iam-permissions.md\">https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/docs/iam-permissions.md</a></li>\n</ul>\n",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "Drops"
            ],
            "date_published": "2021-10-10T13:54:50-03:00",
            "date_modified": "2021-10-15T05:56:08-03:00"
        },
        {
            "id": "https://gutocarvalho.net/instalando-gitlab-runner-no-ubuntu/",
            "url": "https://gutocarvalho.net/instalando-gitlab-runner-no-ubuntu/",
            "title": "DROPS: Instalando GitLab Runner Dind no Ubuntu",
            "summary": "<p>Aprenda a instalar o gitlab-runner para rodar docker DIND.</p>\n",
            "content_html": "<p>Aprenda a instalar o gitlab-runner para rodar docker DIND.</p>\n\n<p><strong>O que são drops?<br><br></strong>São DUMPs mentais rápidos e rasteiros, simples e objetivos – que funcionam. <br><br>Geralmente eu volto para detalhar mais cada passo – com o devido tempo.<br><br>Considere com a mesma qualidade de um rascunho ou uma anotação rápida.<br><br>De qualquer forma comenta ai qquer coisa, os comentários estão ligados nos DROPS ;)</p>\n<hr>\n<p><strong>Instalando docker no Ubuntu</strong><br><br><code>curl https://releases.rancher.com/install-docker/19.03.sh | sh</code><br><code>systemctl enable docker</code><br><code>systemctl start docker</code><br><br><strong>Instalando o GitLab Runner no Ubuntu</strong><br><br><code>curl -LJO \"https://gitlab-runner-downloads.s3.amazonaws.com/latest/deb/gitlab-runner_amd64.deb\"</code><br><code>dpkg -i gitlab-runner_amd64.deb</code><br><code>systemctl enable gitlab-runner</code><br><code>systemctl start gitlab-runner</code><br><br><strong>Registrando um Runner Docker-in-Docker</strong><br><br><code>gitlab-runner register -n \\</code><br><code>  --url https://gitlab.com/ \\</code><br><code>  --registration-token TOKEN \\</code><br><code>  --description \"Runner Guto 1\" \\</code><br><code>  --tag-list docker \\</code><br><code>  --executor docker \\</code><br><code>  --docker-image \"docker:19.03.12\" \\</code><br><code>  --docker-privileged true \\</code><br><code>  --docker-volumes /var/run/docker.sock:/var/run/docker.sock </code><br><strong><br></strong>Crie quantos runners achar necessário, eu costumo reservar 1 vCPU e 1 GB de RAM para cada Runner.<br><br>Um exemplo, se eu subir 4 runners, a VM vai ter 4 vCPUs + 4 GB de RAM só para os Runners, normalmente deixo mais 1 vCPU + 1 GB pro OS e assim fica tranquilo para cenários bem básicos.</p>\n<p><strong>Configurando a concorrência do gitlab-runner</strong><br><br>edite o arquivo<br><br><code>vim  /etc/gitlab-runner/config.toml</code><br><br>altere o número de runners concorrentes para a quantidade que você criou.<br><br><code>concurrent = 4</code><br><br>reinicie o runner</p>\n<p><code>systemctl restart gitlab-runner</code></p>\n<p>ah, tenha certeza que a instância tem recursos que aguentam a demanda de concorrência, tanto do ponto de vista de memória, quanto de processamento e disco.</p>\n<p>[s]<br>Guto</p>",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "Drops"
            ],
            "date_published": "2021-10-09T18:40:29-03:00",
            "date_modified": "2021-10-15T05:56:12-03:00"
        },
        {
            "id": "https://gutocarvalho.net/mesa-com-regulagem-de-altura-eletrica-brasil/",
            "url": "https://gutocarvalho.net/mesa-com-regulagem-de-altura-eletrica-brasil/",
            "title": "Mesa com regulagem de altura elétrica",
            "summary": "<p>Seguem as opções de standing desk que eu encontrei no Brasil.</p>\n",
            "content_html": "<p>Seguem as opções de standing desk que eu encontrei no Brasil.</p>\n\n<p><br><a href=\"https://slik.com.br/\">https://slik.com.br/</a></p>\n<p><a href=\"https://www.geniodesks.com.br\">https://www.geniodesks.com.br</a><br><br><a href=\"https://baherstore.com.br/produto/mesa-reta\">https://baherstore.com.br/produto/mesa-reta</a><br><br>Melhor custo/beneficio até agora é a Baherstore.<br><br>[s]<br>Guto</p>",
            "author": {
                "name": "Guto Carvalho"
            },
            "tags": [
                   "MindNotes"
            ],
            "date_published": "2021-10-09T07:42:06-03:00",
            "date_modified": "2021-10-09T18:43:08-03:00"
        }
    ]
}
